apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: basic-checkpoint-ha-sql-example
  namespace: flink-kubernetes-operator
spec:
  flinkConfiguration:
    env.java.opts: -verbose:gc -XX:+PrintGCDetails
    high-availability: org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory
    high-availability.storageDir: file:///flink-data/ha
    jobmanager.archive.fs.dir: file:///flink-data/completed-jobs
    jobmanager.scheduler: adaptive
    jobstore.dir: file:///flink-data/job-store
    kafka.bootstrap.servers: warpstream-agent.default.svc.cluster.local:9092
    kafka.input.topic: input-topic
    kafka.output.topic: output-topic
    state.checkpoints.dir: file:///flink-data/checkpoints
    state.savepoints.dir: file:///flink-data/savepoints
    taskmanager.numberOfTaskSlots: "2"
  flinkVersion: v1_20
  image: flink:1.20
  job:
    args:
    - -f
    - /opt/flink/sql/job.sql
    entryClass: org.apache.flink.table.client.SqlClient
    jarURI: local:///opt/flink/opt/flink-sql-client-1.20.2.jar
    parallelism: 2
    upgradeMode: stateless
  jobManager:
    resource:
      cpu: 1
      memory: 2048m
  podTemplate:
    spec:
      containers:
      - args:
        - bash
        - -c
        - kubernetes-jobmanager.sh kubernetes-session
        envFrom:
        - secretRef:
            name: flink-warpstream-credentials-secret
        name: flink-main-container
        volumeMounts:
        - mountPath: /flink-data
          name: flink-volume
        - mountPath: /opt/flink/sql/job.sql
          name: flink-sql-script-volume
          subPath: job.sql
        - mountPath: /opt/flink/opt
          name: flink-opt-volume
      initContainers:
      - command:
        - sh
        - -c
        - mkdir -p /opt/flink/sql /flink-data/savepoints /flink-data/checkpoints /flink-data/ha
          /flink-data/completed-jobs  /flink-data/job-store && chmod -R 777 /flink-data
        image: busybox:1.28
        name: init-fs
        securityContext:
          privileged: true
          runAsUser: 0
        volumeMounts:
        - mountPath: /flink-data
          name: flink-volume
      - command:
        - sh
        - -c
        - mkdir -p /tmp/opt && cp -R /opt/flink/opt/. /tmp/opt/ && rm /tmp/opt/flink-table-planner_2.12-1.20.2.jar
          && rm /tmp/opt/flink-s3-fs-hadoop-1.20.2.jar && mkdir -p /opt/flink/opt-new
          && cp -R /tmp/opt/. /opt/flink/opt-new/
        image: flink:1.20
        name: init-remove-conflicting-jars
        volumeMounts:
        - mountPath: /opt/flink/opt-new
          name: flink-opt-volume
      volumes:
      - name: flink-volume
        persistentVolumeClaim:
          claimName: flink-pvc
      - configMap:
          name: flink-sql-script
        name: flink-sql-script-volume
      - emptyDir: {}
        name: flink-opt-volume
  service:
    port: 8081
    targetPort: 8081
    type: ClusterIP
  serviceAccount: flink
  taskManager:
    resource:
      cpu: 1
      memory: 2048m
    serviceAccount: flink
